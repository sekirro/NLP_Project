{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPO微调后大模型的评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一.问题回答的准确性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备部分\n",
    "导入相关的库，定义模型和分词器并初始化，最后定义获取大模型回答的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: rouge in ./.local/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pod/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Your Flash Attention 2 installation seems to be broken?\n",
      "A possible explanation is you have a new CUDA version which isn't\n",
      "yet compatible with FA2? Please file a ticket to Unsloth or FA2.\n",
      "We shall now use Xformers instead, which does not have any performance hits!\n",
      "We found this negligible impact by benchmarking on 1x A100.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "加载模型中...\n",
      "==((====))==  Unsloth 2024.11.11: Fast Qwen2 patching. Transformers:4.46.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.684 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.64s/it]\n",
      "Unsloth 2024.11.11 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载并初始化完成！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "#定义模型和分词器\n",
    "print(\"加载模型中...\")\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"ORPO/finetuned_model/\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "# 初始化模型用于推理\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "print(\"模型加载并初始化完成！\")\n",
    "\n",
    "#生成回答\n",
    "def generate_answer(model, tokenizer, instruction):\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": instruction}\n",
    "    ]\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids, \n",
    "            max_new_tokens=128,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    start_index = generated_text.rfind('Response:')+len('Response:')\n",
    "    generated_text = generated_text[start_index:]\n",
    "    return generated_text\n",
    "\n",
    "# 1. 加载数据\n",
    "test_data = pd.read_csv('shared-nvme/datasets/achieve/reward_test/test_csv/reward_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 ROUGE  \n",
    "主要通过计算 n-gram 的重叠来评估文本的质量。  \n",
    "更关注召回率，适合评估生成文本的覆盖率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:27<00:00,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "平均ROUGE分数:\n",
      "rouge-1-p: 0.0200\n",
      "rouge-1-r: 0.0200\n",
      "rouge-1-f: 0.0200\n",
      "rouge-2-p: 0.0000\n",
      "rouge-2-r: 0.0000\n",
      "rouge-2-f: 0.0000\n",
      "rouge-l-p: 0.0200\n",
      "rouge-l-r: 0.0200\n",
      "rouge-l-f: 0.0200\n",
      "\n",
      "部分示例结果:\n",
      "                                         instruction  \\\n",
      "0                                    肛门病变可能是什么疾病的症状?   \n",
      "1  白带增多发黄怎么个情况？，最近几天，感觉自己的内裤一天下来会有比较多偏黄的粘液痕迹。刚开始以...   \n",
      "2                                      天雄的药用植物栽培是什么?   \n",
      "3      药流后有巧克力白带是没流干净吗，意外怀孕怎么办伤害比较小请问药流后有巧克力白带是没流干净吗   \n",
      "4                                         膺窗穴的定位是什么?   \n",
      "\n",
      "                                           generated  rouge-1-f  rouge-2-f  \\\n",
      "0                          结肠癌；结直肠癌；痔；肛周脓肿；大肠癌；肛瘘；肛裂        0.0        0.0   \n",
      "1  你的情况考虑是细菌性阴道炎，建议去医院做白带常规仔细检查诊断后在医生指导下用药治疗，平时留意...        0.0        0.0   \n",
      "2  1、生长习性：天雄为多年生草本，高约60厘米。根茎粗壮，呈扁柱形或块状，外皮黄褐色，内部白色...        0.0        0.0   \n",
      "3  你好，根据你的情况分析，如果出现褐色分泌物的话，有可能是子宫恢复不好引起的。建议到医院做B超...        0.0        0.0   \n",
      "4                               在胸部，当第四肋间隙，前正中线旁开2寸。        0.0        0.0   \n",
      "\n",
      "   rouge-l-f  \n",
      "0        0.0  \n",
      "1        0.0  \n",
      "2        0.0  \n",
      "3        0.0  \n",
      "4        0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 评估模型并保存详细结果\n",
    "def evaluate_model(model, tokenizer, test_data, num_samples=None):\n",
    "    rouge = Rouge()\n",
    "    \n",
    "    # 创建结果列表\n",
    "    results = []\n",
    "    \n",
    "    # 如果需要抽样\n",
    "    if num_samples and num_samples < len(test_data):\n",
    "        test_data = test_data.sample(n=num_samples, random_state=42)\n",
    "    \n",
    "    # 对每个样本进行评估\n",
    "    for idx, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "        instruction = row['question']\n",
    "        reference = row['response_chosen']\n",
    "        \n",
    "        # 生成回答\n",
    "        generated = generate_answer(model, tokenizer, instruction)\n",
    "        generated = generated.strip()\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            # 计算ROUGE分数\n",
    "            scores = rouge.get_scores(generated, reference)[0]\n",
    "            \n",
    "            # 保存该样本的所有信息\n",
    "            result = {\n",
    "                'instruction': instruction,\n",
    "                'reference': reference,\n",
    "                'generated': generated,\n",
    "                'rouge-1-p': scores['rouge-1']['p'],\n",
    "                'rouge-1-r': scores['rouge-1']['r'],\n",
    "                'rouge-1-f': scores['rouge-1']['f'],\n",
    "                'rouge-2-p': scores['rouge-2']['p'],\n",
    "                'rouge-2-r': scores['rouge-2']['r'],\n",
    "                'rouge-2-f': scores['rouge-2']['f'],\n",
    "                'rouge-l-p': scores['rouge-l']['p'],\n",
    "                'rouge-l-r': scores['rouge-l']['r'],\n",
    "                'rouge-l-f': scores['rouge-l']['f']\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"评估出错 (行 {idx}): {e}\")\n",
    "            print(f\"生成文本: {generated}\")\n",
    "            print(f\"参考文本: {reference}\")\n",
    "            continue\n",
    "    \n",
    "    # 转换为DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # 计算平均分数\n",
    "    avg_scores = {\n",
    "        'rouge-1-p': results_df['rouge-1-p'].mean(),\n",
    "        'rouge-1-r': results_df['rouge-1-r'].mean(),\n",
    "        'rouge-1-f': results_df['rouge-1-f'].mean(),\n",
    "        'rouge-2-p': results_df['rouge-2-p'].mean(),\n",
    "        'rouge-2-r': results_df['rouge-2-r'].mean(),\n",
    "        'rouge-2-f': results_df['rouge-2-f'].mean(),\n",
    "        'rouge-l-p': results_df['rouge-l-p'].mean(),\n",
    "        'rouge-l-r': results_df['rouge-l-r'].mean(),\n",
    "        'rouge-l-f': results_df['rouge-l-f'].mean()\n",
    "    }\n",
    "    \n",
    "    return avg_scores, results_df\n",
    "\n",
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "    # 2. 评估模型\n",
    "    avg_scores, results_df = evaluate_model(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        test_data,\n",
    "        num_samples=100  # 可选：设置样本数量\n",
    "    )\n",
    "    \n",
    "    # 3 保存详细结果\n",
    "    # 3.1 保存每行结果\n",
    "    results_df.to_csv('evaluation/finetuned_model/ORPO_detailed_rouge_scores.csv', index=False)\n",
    "    # 3.2 保存平均分数\n",
    "    avg_scores_df = pd.DataFrame([avg_scores])\n",
    "    avg_scores_df.to_csv('evaluation/finetuned_model/ORPO_average_rouge_scores.csv', index=False)\n",
    "    \n",
    "    # 4. 打印平均分数\n",
    "    print(\"\\n平均ROUGE分数:\")\n",
    "    for metric, score in avg_scores.items():\n",
    "        print(f\"{metric}: {score:.4f}\")\n",
    "    \n",
    "    # 5. 打印部分示例结果\n",
    "    print(\"\\n部分示例结果:\")\n",
    "    print(results_df[['instruction', 'generated', 'rouge-1-f', 'rouge-2-f', 'rouge-l-f']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 BLEU  \n",
    "通过计算生成文本和参考文本之间的 n-gram 精确匹配来评估文本质量。  \n",
    "使用几何平均结合不同长度的 n-gram 匹配，并包含惩罚因子（brevity penalty）。  \n",
    "更关注精确匹配，适合评估翻译的准确性。常用于机器翻译任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting sacrebleu\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/15/d8/e51d35bc863caa19ddeae48dfb890581a19326973ad1c9fa5dcfc63310f7/sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3d/4c/4cb6bb4061910ac74c444be76e7d17dba97d9057030cca2f96947c3f7a0f/portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.12.25)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.24.4)\n",
      "Collecting colorama (from sacrebleu)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: lxml in ./.local/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\n",
      "Installing collected packages: portalocker, colorama, sacrebleu\n",
      "\u001b[33m  WARNING: The script sacrebleu is installed in '/home/pod/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed colorama-0.4.6 portalocker-3.0.0 sacrebleu-2.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:11<00:00,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "部分示例结果:\n",
      "                                         instruction  \\\n",
      "0                                    肛门病变可能是什么疾病的症状?   \n",
      "1  白带增多发黄怎么个情况？，最近几天，感觉自己的内裤一天下来会有比较多偏黄的粘液痕迹。刚开始以...   \n",
      "2                                      天雄的药用植物栽培是什么?   \n",
      "3      药流后有巧克力白带是没流干净吗，意外怀孕怎么办伤害比较小请问药流后有巧克力白带是没流干净吗   \n",
      "4                                         膺窗穴的定位是什么?   \n",
      "\n",
      "                                           generated      bleu  \n",
      "0                           肛门湿疹；直肠息肉；直肠癌；痔病；外痔；肛周脓肿  0.000000  \n",
      "1  根据你的叙述和症状推测，你这种情况有可能是阴道炎引来的。建议你最好去医院做几下白带常规仔细检...  0.000000  \n",
      "2  天雄为多年生草本，高约1m。根状茎粗壮，具节，节上着生须根。叶基生，丛生；叶片线形或披针形，...  1.139582  \n",
      "3  你好，根据你的情况现在是药物流产后的第10天，这个情况建议你可以做B超检查一下，如果子宫内膜...  0.000000  \n",
      "4                               在胸部，平第5肋间隙，前正中线旁开2寸。  0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "#计算 BLEU 分数\n",
    "def evaluate_bleu(model, tokenizer, test_data, num_samples=None):\n",
    "   \n",
    "    results = []\n",
    "    bleu_scores = []\n",
    "\n",
    "    # 如果需要抽样测试集\n",
    "    if num_samples and num_samples < len(test_data):\n",
    "        test_data = test_data.sample(n=num_samples, random_state=42)\n",
    "    \n",
    "    # 遍历测试集，生成答案并计算 BLEU\n",
    "    for idx, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "        instruction = row['question']\n",
    "        reference = row['response_chosen']\n",
    "        \n",
    "        # 生成回答\n",
    "        generated = generate_answer(model, tokenizer, instruction)\n",
    "        generated = generated.strip()\n",
    "        \n",
    "        try:\n",
    "            # 计算 BLEU 分数\n",
    "            bleu_score = sacrebleu.sentence_bleu(generated, [reference]).score\n",
    "            bleu_scores.append(bleu_score)\n",
    "            \n",
    "            # 保存结果\n",
    "            results.append({\n",
    "                'instruction': instruction,\n",
    "                'reference': reference,\n",
    "                'generated': generated,\n",
    "                'bleu': bleu_score\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"行 {idx} 出错: {e}\")\n",
    "            continue\n",
    "\n",
    "    # 转换为 DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # 计算平均 BLEU 分数\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
    "\n",
    "    return avg_bleu, results_df\n",
    "\n",
    "# # 加载测试数据\n",
    "# test_data = pd.read_csv('shared-nvme/datasets/achieve/finetune_test/test_csv/finetune_test.csv')\n",
    "\n",
    "# 计算 BLEU 分数\n",
    "avg_bleu, results_df = evaluate_bleu(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    test_data,\n",
    "    num_samples=100  # 可选：限制样本数量\n",
    ")\n",
    "\n",
    "# 保存详细分数结果\n",
    "results_df.to_csv('evaluation/finetuned_model/ORPO_detailed_bleu_scores.csv', index=False)\n",
    "\n",
    "# 保存平均分数结果\n",
    "avg_bleu_df = pd.DataFrame([{\"average_bleu\": avg_bleu}])\n",
    "avg_bleu_df.to_csv('evaluation/finetuned_model/ORPO_average_bleu_score.csv', index=False)\n",
    "\n",
    "\n",
    "# 打印部分示例\n",
    "print(\"\\n部分示例结果:\")\n",
    "print(results_df[['instruction', 'generated', 'bleu']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLEU 更关注精确匹配，适合评估翻译的准确性。  \n",
    "而METEOR考虑了词序和同义词替换，更关注语义相似性，因此更适合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 METEOR  \n",
    "通过计算词级别的匹配，包括精确匹配、词干匹配和同义词匹配。  \n",
    "使用词序和词义信息来评估文本质量，结合了精确度和召回率。  \n",
    "更关注语义相似性，适合评估生成文本的内容相关性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting nltk\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.10/site-packages (from nltk) (4.67.1)\n",
      "Installing collected packages: nltk\n",
      "\u001b[33m  WARNING: The script nltk is installed in '/home/pod/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed nltk-3.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/pod/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /home/pod/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK资源下载完毕！\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# 下载 NLTK 资源\n",
    "nltk.download('wordnet')  # 用于支持 WordNet 词汇库\n",
    "nltk.download('omw-1.4')  # 用于支持多语言功能\n",
    "print(\"NLTK资源下载完毕！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:06<00:00,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "平均 METEOR 分数:\n",
      "METEOR: 0.0100\n",
      "\n",
      "部分示例结果:\n",
      "                                         instruction  \\\n",
      "0                                    肛门病变可能是什么疾病的症状?   \n",
      "1  白带增多发黄怎么个情况？，最近几天，感觉自己的内裤一天下来会有比较多偏黄的粘液痕迹。刚开始以...   \n",
      "2                                      天雄的药用植物栽培是什么?   \n",
      "3      药流后有巧克力白带是没流干净吗，意外怀孕怎么办伤害比较小请问药流后有巧克力白带是没流干净吗   \n",
      "4                                         膺窗穴的定位是什么?   \n",
      "\n",
      "                                           generated  meteor  \n",
      "0                                       直肠癌；痔病；肛瘘；肛裂     0.0  \n",
      "1  根据你的叙述，考虑是阴道炎的可能性大，建议到医院做分泌物仔细检查明确病因后对症治疗，平时注意...     0.0  \n",
      "2  天雄是薯蓣科薯蓣属的植物，是中国的特有植物。分布于中国大陆的陕西、甘肃、河南、四川等地，生长...     0.0  \n",
      "3  你好，根据你描述的情况看来如果药物流产以后有褐色的分泌物，证明宫腔内还是有残存的，可以做B超...     0.0  \n",
      "4                                     在胸骨中线上，平第四肋间隙。     0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import traceback  # 导入 traceback 模块以获取完整的错误堆栈信息\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "def evaluate_meteor(model, tokenizer, test_data, num_samples=None):\n",
    "    \"\"\"\n",
    "    计算 METEOR 分数，确保 hypothesis 和 reference 是分词后的列表\n",
    "    :param model: 已加载的模型\n",
    "    :param tokenizer: 已加载的分词器\n",
    "    :param test_data: 测试数据集（DataFrame）\n",
    "    :param num_samples: 可选，限制评估样本数量\n",
    "    :return: 平均 METEOR 分数和结果 DataFrame\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    meteor_scores = []\n",
    "\n",
    "    # 如果需要抽样\n",
    "    if num_samples and num_samples < len(test_data):\n",
    "        test_data = test_data.sample(n=num_samples, random_state=42)\n",
    "    \n",
    "    # 遍历测试数据集\n",
    "    for idx, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "        instruction = row['question']\n",
    "        reference = row['response_chosen']\n",
    "        \n",
    "        # 使用模型生成回答\n",
    "        generated = generate_answer(model, tokenizer, instruction)\n",
    "        generated = generated.strip()\n",
    "\n",
    "        try:\n",
    "            # 分词处理\n",
    "            reference_tokens = reference.split()  # 将参考答案分词\n",
    "            generated_tokens = generated.split()  # 将生成文本分词\n",
    "\n",
    "            # 计算 METEOR 分数\n",
    "#             score = meteor_score([reference], generated)\n",
    "            score = meteor_score([reference_tokens], generated_tokens)\n",
    "\n",
    "            meteor_scores.append(score)\n",
    "            \n",
    "            # 保存详细结果\n",
    "            results.append({\n",
    "                'instruction': instruction,\n",
    "                'reference': reference,\n",
    "                'generated': generated,\n",
    "                'meteor': score\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"行 {idx} 出错: {e}\")\n",
    "            print(\"错误堆栈:\")\n",
    "            traceback.print_exc()  # 打印完整的错误堆栈信息\n",
    "            continue\n",
    "\n",
    "    # 转换为 DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # 计算平均 METEOR 分数\n",
    "    avg_meteor = sum(meteor_scores) / len(meteor_scores) if meteor_scores else 0\n",
    "\n",
    "    return avg_meteor, results_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 加载测试数据\n",
    "# test_data = pd.read_csv('shared-nvme/datasets/achieve/finetune_test/test_csv/finetune_test.csv')\n",
    "\n",
    "# 调用 METEOR 评估逻辑\n",
    "avg_meteor, results_df = evaluate_meteor(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    test_data,\n",
    "    num_samples=100  # 限制样本数量\n",
    ")\n",
    "\n",
    "\n",
    "# 保存详细结果到 CSV 文件\n",
    "results_df.to_csv('evaluation/finetuned_model/ORPO_detailed_meteor_scores.csv', index=False)\n",
    "# 将平均分数保存到单独的 CSV 文件\n",
    "avg_meteor_df = pd.DataFrame([{\"average_meteor\": avg_meteor}])\n",
    "avg_meteor_df.to_csv('evaluation/finetuned_model/ORPO_average_meteor_score.csv', index=False)\n",
    "\n",
    "# 打印并保存平均 METEOR 分数\n",
    "print(\"\\n平均 METEOR 分数:\")\n",
    "print(f\"METEOR: {avg_meteor:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# 打印部分示例结果\n",
    "print(\"\\n部分示例结果:\")\n",
    "print(results_df[['instruction', 'generated', 'meteor']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 BERT-Cosin Similarity  \n",
    "BERTScore 使用 BERT 模型来计算生成文本和参考文本之间的语义相似性。  \n",
    "通过 BERT 的上下文信息来评估文本质量，更关注语义相似性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Similarity: 100%|██████████| 100/100 [04:46<00:00,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "平均余弦相似度:\n",
      "Cosine Similarity: 0.9290\n",
      "\n",
      "部分示例结果:\n",
      "                                         instruction  \\\n",
      "0                                    肛门病变可能是什么疾病的症状?   \n",
      "1  白带增多发黄怎么个情况？，最近几天，感觉自己的内裤一天下来会有比较多偏黄的粘液痕迹。刚开始以...   \n",
      "2                                      天雄的药用植物栽培是什么?   \n",
      "3      药流后有巧克力白带是没流干净吗，意外怀孕怎么办伤害比较小请问药流后有巧克力白带是没流干净吗   \n",
      "4                                         膺窗穴的定位是什么?   \n",
      "\n",
      "                                           generated  cosine_similarity  \n",
      "0                                      肛门瘙痒症；痔病；直肠脱垂           0.963428  \n",
      "1  白带增多泛黄，这种情况可能会是因为阴道炎导致的，建议您及时去医院检查一下白带常规，明确病因后...           0.991529  \n",
      "2  天雄为多年生草本。根茎粗壮，长圆柱形，有分枝，节间膨大呈纺锤状，外皮棕褐色至灰棕色，内部白色...           0.835396  \n",
      "3  你好，一般在药流后1周左右就会有褐色分泌物的。如果超过这个时间的话，就可能是没有流干净了。建...           0.994219  \n",
      "4                               在胸部，当第4肋间隙，前正中线旁开2寸。           0.991391  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# 指定本地模型路径\n",
    "local_model_path = \"shared-nvme/llm_models/models--google-bert--bert-base-uncased\"  \n",
    "\n",
    "# 加载本地 BERT 模型和分词器\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "bert_model = AutoModel.from_pretrained(local_model_path).to(\"cuda\")\n",
    "\n",
    "# 显式设置分词器的 pad_token，避免默认使用 eos_token\n",
    "if bert_tokenizer.pad_token is None:\n",
    "    bert_tokenizer.pad_token = bert_tokenizer.eos_token\n",
    "\n",
    "def compute_sentence_embedding(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    计算给定文本的句子嵌入\n",
    "    :param text: 输入文本\n",
    "    :param model: 已加载的 BERT 模型\n",
    "    :param tokenizer: 已加载的分词器\n",
    "    :return: 文本的句子嵌入\n",
    "    \"\"\"\n",
    "    # 对文本进行编码\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # 确保包含 attention_mask\n",
    "    inputs['attention_mask'] = inputs.get('attention_mask', None)\n",
    "\n",
    "\n",
    "    # 获取模型输出\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # 使用 [CLS] token 的嵌入作为句子嵌入\n",
    "    sentence_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return sentence_embedding\n",
    "\n",
    "def evaluate_bert_similarity(test_data, num_samples=None):\n",
    "    \"\"\"\n",
    "    使用 BERT 计算生成文本和参考文本之间的余弦相似度\n",
    "    :param test_data: 测试数据集（DataFrame）\n",
    "    :param num_samples: 可选，限制评估样本数量\n",
    "    :return: 平均余弦相似度和结果 DataFrame\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    cosine_similarities = []\n",
    "\n",
    "    # 如果需要抽样\n",
    "    if num_samples and num_samples < len(test_data):\n",
    "        test_data = test_data.sample(n=num_samples, random_state=42)\n",
    "    \n",
    "    # 遍历测试数据集\n",
    "    for idx, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Calculating Similarity\"):\n",
    "        instruction = row['question']\n",
    "        reference = row['response_chosen']\n",
    "        \n",
    "        # 使用已有的 generate_answer 生成回答\n",
    "        generated = generate_answer(model, tokenizer, instruction)\n",
    "        generated = generated.strip()\n",
    "\n",
    "        try:\n",
    "            # 计算句子嵌入\n",
    "            reference_embedding = compute_sentence_embedding(reference, bert_model, bert_tokenizer)\n",
    "            generated_embedding = compute_sentence_embedding(generated, bert_model, bert_tokenizer)\n",
    "\n",
    "            # 计算余弦相似度\n",
    "            cosine_similarity = torch.nn.functional.cosine_similarity(\n",
    "                reference_embedding, generated_embedding\n",
    "            ).item()\n",
    "            cosine_similarities.append(cosine_similarity)\n",
    "\n",
    "            # 保存详细结果\n",
    "            results.append({\n",
    "                'instruction': instruction,\n",
    "                'reference': reference,\n",
    "                'generated': generated,\n",
    "                'cosine_similarity': cosine_similarity\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"行 {idx} 出错: {e}\")\n",
    "            continue\n",
    "\n",
    "    # 转换为 DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # 计算平均余弦相似度\n",
    "    avg_cosine_similarity = sum(cosine_similarities) / len(cosine_similarities) if cosine_similarities else 0\n",
    "\n",
    "    return avg_cosine_similarity, results_df\n",
    "\n",
    "\n",
    "# # 加载测试数据\n",
    "# test_data = pd.read_csv('shared-nvme/datasets/achieve/finetune_test/test_csv/finetune_test.csv')\n",
    "\n",
    "# 调用 BERT 相似度评估逻辑\n",
    "avg_cosine_similarity, results_df = evaluate_bert_similarity(\n",
    "    test_data,\n",
    "    num_samples=100  # 限制样本数量\n",
    ")\n",
    "\n",
    "# 保存详细结果到 CSV 文件\n",
    "results_df.to_csv('evaluation/finetuned_model/ORPO_detailed_bert_cosine_similarity.csv', index=False)\n",
    "\n",
    "# 保存平均余弦相似度到 CSV 文件\n",
    "avg_cosine_similarity_df = pd.DataFrame([{\"average_cosine_similarity\": avg_cosine_similarity}])\n",
    "avg_cosine_similarity_df.to_csv('evaluation/finetuned_model/ORPO_average_bert_cosine_similarity.csv', index=False)\n",
    "\n",
    "# 打印并保存平均余弦相似度\n",
    "print(\"\\n平均余弦相似度:\")\n",
    "print(f\"Cosine Similarity: {avg_cosine_similarity:.4f}\")\n",
    "\n",
    "# 打印部分示例结果\n",
    "print(\"\\n部分示例结果:\")\n",
    "print(results_df[['instruction', 'generated', 'cosine_similarity']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到使用在中文上表现优秀的的BERT语言模型，可以更好的处理同义词、语义上的相似度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 BGE-Cosin Similarity\n",
    " bge-large-zh-v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating BGE Similarity: 100%|██████████| 100/100 [04:38<00:00,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "平均余弦相似度:\n",
      "Cosine Similarity: 0.7089\n",
      "\n",
      "部分示例结果:\n",
      "                                         instruction  \\\n",
      "0                                    肛门病变可能是什么疾病的症状?   \n",
      "1  白带增多发黄怎么个情况？，最近几天，感觉自己的内裤一天下来会有比较多偏黄的粘液痕迹。刚开始以...   \n",
      "2                                      天雄的药用植物栽培是什么?   \n",
      "3      药流后有巧克力白带是没流干净吗，意外怀孕怎么办伤害比较小请问药流后有巧克力白带是没流干净吗   \n",
      "4                                         膺窗穴的定位是什么?   \n",
      "\n",
      "                                           generated  cosine_similarity  \n",
      "0                                   直肠炎；肛门裂伤；肛门湿疹；肛瘘           0.308477  \n",
      "1  你的情况考虑是阴道炎引来的，建议你可以用妇炎洁擦洗外阴，然后去医院做白带常规仔细检查，根据仔...           0.913396  \n",
      "2  天雄为百合科植物。分布于山东、江苏、安徽、浙江、江西、福建、台湾、河南、湖北、湖南、广东、广...           0.718531  \n",
      "3  你好，一般在流产后一周内阴道出血会逐渐停止，如果超过了一周仍有出血，而且血量较多的话，有可能...           0.765814  \n",
      "4                            在胸骨中下部，平第4肋间隙，前正中线旁开2寸。           0.838496  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# 指定本地模型路径\n",
    "local_model_path = \"shared-nvme/llm_models/models--BAAI--bge-large-zh-v1.5\"  # 替换为您的本地路径\n",
    "\n",
    "# 加载本地 BGE 模型和分词器\n",
    "bge_tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "bge_model = AutoModel.from_pretrained(local_model_path).to(\"cuda\")\n",
    "\n",
    "# # 显式设置分词器的 pad_token\n",
    "# if bge_tokenizer.pad_token is None:\n",
    "#     bge_tokenizer.pad_token = bge_tokenizer.eos_token  # 使用 eos_token 作为 pad_token（如有必要）\n",
    "\n",
    "def compute_sentence_embedding_bge(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    使用 BGE 模型计算文本的句子嵌入\n",
    "    :param text: 输入文本\n",
    "    :param model: 已加载的 BGE 模型\n",
    "    :param tokenizer: 已加载的分词器\n",
    "    :return: 文本的句子嵌入\n",
    "    \"\"\"\n",
    "    # 对文本进行编码\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # 获取 BGE 模型的输出\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # 获取池化嵌入作为句子特征\n",
    "    sentence_embedding = outputs.last_hidden_state[:, 0, :]  # 使用 [CLS] 作为句子特征\n",
    "    return sentence_embedding\n",
    "\n",
    "def evaluate_bge_similarity(test_data, num_samples=None):\n",
    "    \"\"\"\n",
    "    使用 BGE 模型计算生成文本和参考文本之间的余弦相似度\n",
    "    :param test_data: 测试数据集（DataFrame）\n",
    "    :param num_samples: 可选，限制评估样本数量\n",
    "    :return: 平均余弦相似度和结果 DataFrame\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    cosine_similarities = []\n",
    "\n",
    "    # 如果需要抽样\n",
    "    if num_samples and num_samples < len(test_data):\n",
    "        test_data = test_data.sample(n=num_samples, random_state=42)\n",
    "    \n",
    "    # 遍历测试数据集\n",
    "    for idx, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Calculating BGE Similarity\"):\n",
    "        instruction = row['question']\n",
    "        reference = row['response_chosen']\n",
    "        \n",
    "        # 使用全局的 generate_answer 函数生成回答\n",
    "        generated = generate_answer(model, tokenizer, instruction)\n",
    "        generated = generated.strip()\n",
    "\n",
    "        try:\n",
    "            # 计算句子嵌入\n",
    "            reference_embedding = compute_sentence_embedding_bge(reference, bge_model, bge_tokenizer)\n",
    "            generated_embedding = compute_sentence_embedding_bge(generated, bge_model, bge_tokenizer)\n",
    "\n",
    "            # 计算余弦相似度\n",
    "            cosine_similarity = torch.nn.functional.cosine_similarity(\n",
    "                reference_embedding, generated_embedding\n",
    "            ).item()\n",
    "            cosine_similarities.append(cosine_similarity)\n",
    "\n",
    "            # 保存详细结果\n",
    "            results.append({\n",
    "                'instruction': instruction,\n",
    "                'reference': reference,\n",
    "                'generated': generated,\n",
    "                'cosine_similarity': cosine_similarity\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"行 {idx} 出错: {e}\")\n",
    "            continue\n",
    "\n",
    "    # 转换为 DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # 计算平均余弦相似度\n",
    "    avg_cosine_similarity = sum(cosine_similarities) / len(cosine_similarities) if cosine_similarities else 0\n",
    "\n",
    "    return avg_cosine_similarity, results_df\n",
    "\n",
    "\n",
    "# # 加载测试数据\n",
    "# test_data = pd.read_csv('shared-nvme/datasets/achieve/finetune_test/test_csv/finetune_test.csv')\n",
    "\n",
    "# 调用 BGE 相似度评估逻辑\n",
    "avg_cosine_similarity, results_df = evaluate_bge_similarity(\n",
    "    test_data,\n",
    "    num_samples=100  # 限制样本数量\n",
    ")\n",
    "\n",
    "# 保存详细结果到 CSV 文件\n",
    "results_df.to_csv('evaluation/finetuned_model/ORPO_detailed_bge_cosine_similarity.csv', index=False)\n",
    "\n",
    "# 保存平均余弦相似度到 CSV 文件\n",
    "avg_cosine_similarity_df = pd.DataFrame([{\"average_cosine_similarity\": avg_cosine_similarity}])\n",
    "avg_cosine_similarity_df.to_csv('evaluation/finetuned_model/ORPO_average_bge_cosine_similarity.csv', index=False)\n",
    "\n",
    "# 打印并保存平均余弦相似度\n",
    "print(\"\\n平均余弦相似度:\")\n",
    "print(f\"Cosine Similarity: {avg_cosine_similarity:.4f}\")\n",
    "\n",
    "# 打印部分示例结果\n",
    "print(\"\\n部分示例结果:\")\n",
    "print(results_df[['instruction', 'generated', 'cosine_similarity']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三.问题回答的流畅性\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity  \n",
    "评估模型的语言流畅性和训练过程的收敛性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Perplexity: 100%|██████████| 100/100 [00:10<00:00,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQR 范围: 下限=0, 上限=57.86283826828003\n",
      "识别到的异常值数量: 27\n",
      "\n",
      "平均 Perplexity:\n",
      "Perplexity: 15.1104\n",
      "\n",
      "部分示例结果:\n",
      "                                                text  perplexity\n",
      "0                                             食管克罗恩病   24.213917\n",
      "1  白带增多泛黄应该是患阴道炎了，而且是细菌性阴道炎的可能性大，你可以用妇科洗剂擦洗外阴阴道，同...    6.597219\n",
      "2  1.气候土壤：天雄喜温暖、湿润和向阳环境，宜选土层深厚肥沃、土质疏松、排水良好的土壤栽种。2...   13.638639\n",
      "3  你的这种情况可能是细菌性或霉菌性阴道炎，可以用苦参或土槿皮煎水熏洗治疗，有一定效果，苦参或土...    1.923973\n",
      "4                                     第3肋间隙，距前正中线4寸。   12.033834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_perplexity(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    使用全局定义的模型和分词器计算文本的 Perplexity\n",
    "    :param text: 输入文本\n",
    "    :param model: 已加载的语言模型\n",
    "    :param tokenizer: 已加载的分词器\n",
    "    :return: Perplexity 值\n",
    "    \"\"\"\n",
    "    # 对文本进行编码\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # 设置输入标签\n",
    "    inputs['labels'] = inputs['input_ids']\n",
    "\n",
    "    # 计算模型的交叉熵损失\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss  # 模型返回的交叉熵损失\n",
    "\n",
    "    # 根据交叉熵损失计算 Perplexity\n",
    "    perplexity = torch.exp(loss).item()\n",
    "    return perplexity\n",
    "\n",
    "\n",
    "def evaluate_perplexity(test_data, model, tokenizer, num_samples=None):\n",
    "    \"\"\"\n",
    "    计算测试数据集中每条文本的 Perplexity，并计算平均值\n",
    "    使用四分位数（IQR）原则识别异常值，对异常值进行平滑处理\n",
    "    :param test_data: 测试数据集（DataFrame）\n",
    "    :param model: 已加载的语言模型\n",
    "    :param tokenizer: 已加载的分词器\n",
    "    :param num_samples: 可选，限制评估样本数量\n",
    "    :return: 平均 Perplexity 和结果 DataFrame\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    perplexities = []\n",
    "\n",
    "    # 如果需要抽样\n",
    "    if num_samples and num_samples < len(test_data):\n",
    "        test_data = test_data.sample(n=num_samples, random_state=42)\n",
    "    \n",
    "    # 遍历测试数据集\n",
    "    for idx, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Calculating Perplexity\"):\n",
    "        reference = row['response_chosen']  # 使用参考文本计算 Perplexity\n",
    "        \n",
    "        try:\n",
    "            # 计算 Perplexity\n",
    "            perplexity = compute_perplexity(reference, model, tokenizer)\n",
    "            perplexities.append(perplexity)\n",
    "\n",
    "            # 保存结果\n",
    "            results.append({\n",
    "                'text': reference,\n",
    "                'perplexity': perplexity\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"行 {idx} 出错: {e}\")\n",
    "            continue\n",
    "\n",
    "    # 转换为 DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # 标记超出初步过滤范围的极端值\n",
    "    perplexity_series = pd.Series(perplexities)\n",
    "    MAX_THRESHOLD = 200  # 初步过滤的最大值阈值\n",
    "    is_extreme = perplexity_series > MAX_THRESHOLD  # 标记极端值\n",
    "\n",
    "    # 替换超出范围的值为临时标记值（如 NaN）\n",
    "    filtered_perplexities = perplexity_series.copy()\n",
    "    filtered_perplexities[is_extreme] = None\n",
    "\n",
    "    \n",
    "    # 计算新的 IQR（四分位间距）\n",
    "    Q1 = filtered_perplexities.quantile(0.25)  # 第 1 四分位数\n",
    "    Q3 = filtered_perplexities.quantile(0.75)  # 第 3 四分位数\n",
    "    IQR = max(Q3 - Q1, 1)  # 确保 IQR 不为 0\n",
    "\n",
    "    # 根据新的 IQR 定义范围\n",
    "    lower_bound = max(Q1 - 1.5 * IQR, 0)  # Perplexity 不可能小于 0\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # 输出调试信息，验证上下限是否合理\n",
    "    print(f\"IQR 范围: 下限={lower_bound}, 上限={upper_bound}\")\n",
    "\n",
    "    # 计算 IQR 内的均值\n",
    "    mean_ppl = perplexity_series[(perplexity_series >= lower_bound) & (perplexity_series <= upper_bound)].mean()\n",
    "\n",
    "    # 计算 IQR 内的均值\n",
    "    mean_ppl = filtered_perplexities.dropna()[\n",
    "        (filtered_perplexities >= lower_bound) & (filtered_perplexities <= upper_bound)\n",
    "    ].mean()\n",
    "\n",
    "    # 对所有极端值（标记值和 IQR 范围外的值）进行平滑处理\n",
    "    smoothed_perplexities = perplexity_series.apply(\n",
    "        lambda x: mean_ppl if pd.isna(x) or x < lower_bound or x > upper_bound else x\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # 输出调试信息，检查异常值是否被识别\n",
    "    num_anomalies = (perplexity_series < lower_bound).sum() + (perplexity_series > upper_bound).sum()\n",
    "    print(f\"识别到的异常值数量: {num_anomalies}\")\n",
    "\n",
    "    # 更新 DataFrame 的 Perplexity 列\n",
    "    results_df['perplexity'] = smoothed_perplexities\n",
    "\n",
    "    # 计算最终的平均 Perplexity\n",
    "    avg_perplexity = smoothed_perplexities.mean()\n",
    "\n",
    "    return avg_perplexity, results_df\n",
    "\n",
    "\n",
    "# 调用 Perplexity 评估逻辑\n",
    "avg_perplexity, results_df = evaluate_perplexity(\n",
    "    test_data,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    num_samples=100  # 限制样本数量\n",
    ")\n",
    "\n",
    "# 保存详细结果到 CSV 文件\n",
    "results_df.to_csv('evaluation/finetuned_model/ORPO_detailed_perplexity.csv', index=False)\n",
    "\n",
    "# 保存平均 Perplexity 到 CSV 文件\n",
    "avg_perplexity_df = pd.DataFrame([{\"average_perplexity\": avg_perplexity}])\n",
    "avg_perplexity_df.to_csv('evaluation/finetuned_model/ORPO_average_perplexity.csv', index=False)\n",
    "\n",
    "# 打印并保存平均 Perplexity\n",
    "print(\"\\n平均 Perplexity:\")\n",
    "print(f\"Perplexity: {avg_perplexity:.4f}\")\n",
    "\n",
    "# 打印部分示例结果\n",
    "print(\"\\n部分示例结果:\")\n",
    "print(results_df[['text', 'perplexity']].head())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
