{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r': 0.631578947368421, 'p': 0.5217391304347826, 'f': 0.571428566473923}\n",
      "{'r': 0.2777777777777778, 'p': 0.20833333333333334, 'f': 0.23809523319727902}\n",
      "{'r': 0.47368421052631576, 'p': 0.391304347826087, 'f': 0.42857142361678}\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge \n",
    "\n",
    "hypothesis = \"\"\"\n",
    "  Anna searches for her favorite book 'The Silent Stars', and Ben admits \n",
    "  he borrowed it without asking, leading to a plan to discuss it later\n",
    "\"\"\"\n",
    "reference = \"\"\"\n",
    "  Anna realizes Ben borrowed her favorite book without asking, and they \n",
    "  agree to discuss it once he's finished reading\n",
    "\"\"\"\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(hypothesis, reference)\n",
    "\n",
    "print(scores[0][\"rouge-1\"])\n",
    "print(scores[0][\"rouge-2\"])\n",
    "print(scores[0][\"rouge-l\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=0.52, recall=0.65, fmeasure=0.5777777777777778), 'rouge2': Score(precision=0.20833333333333334, recall=0.2631578947368421, fmeasure=0.23255813953488372), 'rougeL': Score(precision=0.36, recall=0.45, fmeasure=0.39999999999999997)}\n"
     ]
    }
   ],
   "source": [
    "# 使用\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(reference, hypothesis)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU分数: 100.00000000000004\n"
     ]
    }
   ],
   "source": [
    "# BLEU评估\n",
    "import sacrebleu\n",
    "\n",
    "references = [\"今天天气真不错\"]\n",
    "hypothesis = \"今天天气真不错\"\n",
    "\n",
    "# BLEU\n",
    "bleu = sacrebleu.corpus_bleu(\n",
    "    [hypothesis],\n",
    "    [references],\n",
    "    tokenize='zh'\n",
    ")\n",
    "print(f\"BLEU分数: {bleu.score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR score: 0.996\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate import meteor_score\n",
    "\n",
    "# 准备英文测试文本\n",
    "reference = \"The weather is nice today\"\n",
    "hypothesis = \"The weather is nice today\"\n",
    "\n",
    "# 简单分词（按空格分）\n",
    "reference_tokens = reference.split()\n",
    "hypothesis_tokens = hypothesis.split()\n",
    "\n",
    "# 计算METEOR分数\n",
    "score = meteor_score.meteor_score([reference_tokens], hypothesis_tokens)\n",
    "print(f\"METEOR score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99332238ffcb492aa8fe1c39d0700bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c55c90fd93414da68ce6edff61be70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "class TextSimilarity:\n",
    "    def __init__(self):\n",
    "        # 初始化 TF-IDF\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        \n",
    "        # 初始化预训练模型（可选）\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModel.from_pretrained(self.model_name).to(self.device)\n",
    "    \n",
    "    def tfidf_similarity(self, text1: str, text2: str) -> float:\n",
    "        \"\"\"使用TF-IDF计算文本相似度\"\"\"\n",
    "        # 构建TF-IDF矩阵\n",
    "        tfidf_matrix = self.tfidf.fit_transform([text1, text2])\n",
    "        # 计算余弦相似度\n",
    "        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "        return float(similarity[0][0])\n",
    "    \n",
    "    def embedding_similarity(self, text1: str, text2: str) -> float:\n",
    "        \"\"\"使用预训练模型计算文本嵌入相似度\"\"\"\n",
    "        # 编码文本\n",
    "        inputs1 = self.tokenizer(text1, return_tensors=\"pt\", \n",
    "                               truncation=True, max_length=512).to(self.device)\n",
    "        inputs2 = self.tokenizer(text2, return_tensors=\"pt\", \n",
    "                               truncation=True, max_length=512).to(self.device)\n",
    "        \n",
    "        # 获取文本嵌入\n",
    "        with torch.no_grad():\n",
    "            embedding1 = self.model(**inputs1).last_hidden_state.mean(dim=1)\n",
    "            embedding2 = self.model(**inputs2).last_hidden_state.mean(dim=1)\n",
    "        \n",
    "        # 计算余弦相似度\n",
    "        similarity = torch.nn.functional.cosine_similarity(embedding1, embedding2)\n",
    "        return float(similarity[0])\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化相似度计算器\n",
    "    similarity_calculator = TextSimilarity()\n",
    "    \n",
    "    # 测试用例\n",
    "    test_cases = [\n",
    "        # 完全相同的句子\n",
    "        (\"今天天气真好\", \"今天天气真好\"),\n",
    "        # 相似的句子\n",
    "        (\"今天天气真好\", \"今天天气不错\"),\n",
    "        # 部分相关的句子\n",
    "        (\"我喜欢吃苹果\", \"我喜欢吃香蕉\"),\n",
    "        # 不相关的句子\n",
    "        (\"今天天气真好\", \"我喜欢吃苹果\"),\n",
    "        # 英文测试\n",
    "        (\"The weather is nice today\", \"The weather is good today\"),\n",
    "        # 长文本测试\n",
    "        (\"这是一个很长的句子，包含了很多内容，说明了很多事情\", \n",
    "         \"这也是一个很长的句子，同样包含很多内容，也说明了很多事情\"),\n",
    "    ]\n",
    "    \n",
    "    # 运行测试\n",
    "    print(\"测试结果：\")\n",
    "    print(\"-\" * 50)\n",
    "    for text1, text2 in test_cases:\n",
    "        print(f\"\\n文本1: {text1}\")\n",
    "        print(f\"文本2: {text2}\")\n",
    "        \n",
    "        # TF-IDF 相似度\n",
    "        tfidf_sim = similarity_calculator.tfidf_similarity(text1, text2)\n",
    "        print(f\"TF-IDF 相似度: {tfidf_sim:.4f}\")\n",
    "        \n",
    "        # 预训练模型相似度\n",
    "        emb_sim = similarity_calculator.embedding_similarity(text1, text2)\n",
    "        print(f\"预训练模型相似度: {emb_sim:.4f}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各句子的困惑度:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "exp(): argument 'input' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m各句子的困惑度:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m test_texts:\n\u001b[1;32m---> 41\u001b[0m     ppl \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_perplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m文本: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerplexity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mppl\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m, in \u001b[0;36mcompute_perplexity\u001b[1;34m(model, tokenizer, text)\u001b[0m\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 返回perplexity\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mTypeError\u001b[0m: exp(): argument 'input' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def compute_perplexity(model, tokenizer, text):\n",
    "    # 将文本转换为tensor\n",
    "    encodings = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # 计算\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "    # 返回perplexity\n",
    "    return torch.exp(loss).item()\n",
    "\n",
    "# 使用示例\n",
    "model_path = \"Qwen/Qwen2.5-0.5B-Instruct\"  # 你的模型路径\n",
    "\n",
    "# 加载模型和tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 测试文本\n",
    "test_texts = [\n",
    "    \"今天天气真不错\",\n",
    "    \"人工智能正在快速发展\",\n",
    "    \"这是一个测试句子\"\n",
    "]\n",
    "\n",
    "# 计算每个文本的perplexity\n",
    "print(\"各句子的困惑度:\")\n",
    "for text in test_texts:\n",
    "    ppl = compute_perplexity(model, tokenizer, text)\n",
    "    print(f\"文本: {text}\")\n",
    "    print(f\"Perplexity: {ppl:.2f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 计算平均perplexity\n",
    "avg_ppl = sum(compute_perplexity(model, tokenizer, text) for text in test_texts) / len(test_texts)\n",
    "print(f\"\\n平均困惑度: {avg_ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_answer(model, tokenizer, instruction):\n",
    "    \"\"\"生成回答\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": instruction}\n",
    "    ]\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids, \n",
    "            max_new_tokens=128,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "def evaluate_model(model, tokenizer, test_data, num_samples=None):\n",
    "    \"\"\"评估模型并保存详细结果\"\"\"\n",
    "    rouge = Rouge()\n",
    "    \n",
    "    # 创建结果列表\n",
    "    results = []\n",
    "    \n",
    "    # 如果需要抽样\n",
    "    if num_samples and num_samples < len(test_data):\n",
    "        test_data = test_data.sample(n=num_samples, random_state=42)\n",
    "    \n",
    "    # 对每个样本进行评估\n",
    "    for idx, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "        instruction = row['instruction']\n",
    "        reference = row['output']\n",
    "        \n",
    "        # 生成回答\n",
    "        generated = generate_answer(model, tokenizer, instruction)\n",
    "        \n",
    "        try:\n",
    "            # 计算ROUGE分数\n",
    "            scores = rouge.get_scores(generated, reference)[0]\n",
    "            \n",
    "            # 保存该样本的所有信息\n",
    "            result = {\n",
    "                'instruction': instruction,\n",
    "                'reference': reference,\n",
    "                'generated': generated,\n",
    "                'rouge-1-p': scores['rouge-1']['p'],\n",
    "                'rouge-1-r': scores['rouge-1']['r'],\n",
    "                'rouge-1-f': scores['rouge-1']['f'],\n",
    "                'rouge-2-p': scores['rouge-2']['p'],\n",
    "                'rouge-2-r': scores['rouge-2']['r'],\n",
    "                'rouge-2-f': scores['rouge-2']['f'],\n",
    "                'rouge-l-p': scores['rouge-l']['p'],\n",
    "                'rouge-l-r': scores['rouge-l']['r'],\n",
    "                'rouge-l-f': scores['rouge-l']['f']\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"评估出错 (行 {idx}): {e}\")\n",
    "            print(f\"生成文本: {generated}\")\n",
    "            print(f\"参考文本: {reference}\")\n",
    "            continue\n",
    "    \n",
    "    # 转换为DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # 计算平均分数\n",
    "    avg_scores = {\n",
    "        'rouge-1': results_df['rouge-1-f'].mean(),\n",
    "        'rouge-2': results_df['rouge-2-f'].mean(),\n",
    "        'rouge-l': results_df['rouge-l-f'].mean()\n",
    "    }\n",
    "    \n",
    "    return avg_scores, results_df\n",
    "\n",
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. 加载数据\n",
    "    test_data = pd.read_csv('your_data.csv')\n",
    "    \n",
    "    # 2. 评估模型\n",
    "    avg_scores, results_df = evaluate_model(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        test_data,\n",
    "        num_samples=100  # 可选：设置样本数量\n",
    "    )\n",
    "    \n",
    "    # 3. 保存详细结果\n",
    "    results_df.to_csv('detailed_rouge_scores.csv', index=False)\n",
    "    \n",
    "    # 4. 打印平均分数\n",
    "    print(\"\\n平均ROUGE分数:\")\n",
    "    for metric, score in avg_scores.items():\n",
    "        print(f\"{metric}: {score:.4f}\")\n",
    "    \n",
    "    # 5. 打印部分示例结果\n",
    "    print(\"\\n部分示例结果:\")\n",
    "    print(results_df[['instruction', 'generated', 'rouge-1-f', 'rouge-2-f', 'rouge-l-f']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
