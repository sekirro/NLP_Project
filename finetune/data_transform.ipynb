{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集链接：https://www.kaggle.com/datasets/thedevastator/chinese-medical-dialogue-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始检测文件编码...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "检测文件编码: 100%|██████████| 9/9 [00:00<00:00, 91.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "文件名: finetune_test.csv\n",
      "编码格式: None\n",
      "置信度: 0.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "文件名: finetune_train.csv\n",
      "编码格式: utf-8\n",
      "置信度: 99.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "文件名: finetune_validation.csv\n",
      "编码格式: utf-8\n",
      "置信度: 99.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "文件名: pretrain_test.csv\n",
      "编码格式: utf-8\n",
      "置信度: 99.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "文件名: pretrain_train.csv\n",
      "编码格式: utf-8\n",
      "置信度: 99.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "文件名: pretrain_validation.csv\n",
      "编码格式: utf-8\n",
      "置信度: 99.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "文件名: reward_test.csv\n",
      "编码格式: utf-8\n",
      "置信度: 99.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "文件名: reward_train.csv\n",
      "编码格式: utf-8\n",
      "置信度: 99.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "文件名: reward_validation.csv\n",
      "编码格式: utf-8\n",
      "置信度: 99.00%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def detect_file_encoding(file_path):\n",
    "    \"\"\"检测文件的编码格式\"\"\"\n",
    "    # 读取文件的一部分来检测编码（避免大文件读取全部内容）\n",
    "    with open(file_path, 'rb') as file:\n",
    "        # 读取前10000个字节进行检测\n",
    "        raw_data = file.read(10000)\n",
    "        result = chardet.detect(raw_data)\n",
    "        \n",
    "    return {\n",
    "        'file_name': os.path.basename(file_path),\n",
    "        'encoding': result['encoding'],\n",
    "        'confidence': result['confidence']\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # 获取所有CSV文件\n",
    "    csv_files = glob.glob('D:/Desktop/finetune/archive/*.csv')\n",
    "    \n",
    "    print(\"开始检测文件编码...\")\n",
    "    \n",
    "    # 遍历检测每个CSV文件\n",
    "    for csv_file in tqdm(csv_files, desc=\"检测文件编码\"):\n",
    "        try:\n",
    "            result = detect_file_encoding(csv_file)\n",
    "            print(f\"\\n文件名: {result['file_name']}\")\n",
    "            print(f\"编码格式: {result['encoding']}\")\n",
    "            print(f\"置信度: {result['confidence']:.2%}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"处理文件 {csv_file} 时出错: {str(e)}\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13686\\AppData\\Local\\Temp\\ipykernel_23664\\145930813.py:3: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          instruction                                             output\n",
      "0         血热的临床表现是什么?  初发或复发病不久。皮疹发展迅速，呈点滴状、钱币状或混合状。常见丘疹、斑丘疹、大小不等的斑片，...\n",
      "1  帕金森叠加综合征的辅助治疗有些什么？                       综合治疗；康复训练；生活护理指导；低频重复经颅磁刺激治疗\n",
      "2    卵巢癌肉瘤的影像学检查有些什么？                       超声漏诊；声像图；MR检查；肿物超声；术前超声；CT检查\n",
      "3        婴儿耳朵湿疹流水怎么治疗  婴儿湿疹又称“奶癣”，是常见的一种过敏性皮肤病，多在生后2－3个月发病，1岁以后逐渐好转。湿...\n",
      "4      低T3综合征的并发症是什么？                               心力衰竭；甲状腺结节；糖尿病；感染性休克\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "csv_file = 'D:/Desktop/finetune/archive/finetune_train.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "df_cleaned = df.drop('input', axis=1)\n",
    "df_cleaned.to_csv('D:/Desktop/finetune/archive/finetune_train.csv', index=False)\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV文件列表: ['D:/Desktop/NLP/finetune/archive\\\\finetune_test.csv', 'D:/Desktop/NLP/finetune/archive\\\\finetune_train.csv', 'D:/Desktop/NLP/finetune/archive\\\\finetune_validation.csv', 'D:/Desktop/NLP/finetune/archive\\\\pretrain_test.csv', 'D:/Desktop/NLP/finetune/archive\\\\pretrain_train.csv', 'D:/Desktop/NLP/finetune/archive\\\\pretrain_validation.csv', 'D:/Desktop/NLP/finetune/archive\\\\reward_test.csv', 'D:/Desktop/NLP/finetune/archive\\\\reward_train.csv', 'D:/Desktop/NLP/finetune/archive\\\\reward_validation.csv']\n",
      "输出目录: D:/Desktop/NLP/finetune/archive_arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换CSV文件:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理文件: D:/Desktop/NLP/finetune/archive\\reward_train.csv\n",
      "数据行数: 3800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9964bd9effa4645935a93482d5bad58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换CSV文件: 100%|██████████| 9/9 [00:02<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已成功保存到: D:/Desktop/NLP/finetune/archive_arrow\\reward_train\n",
      "成功加载数据集，列名: {'train': ['question', 'response_chosen', 'response_rejected']}\n",
      "成功转换: reward_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk, DatasetDict\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 创建输出目录\n",
    "output_base_dir = 'D:/Desktop/NLP/finetune/archive_arrow'\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "# 获取所有CSV文件\n",
    "csv_files = glob.glob(r'D:/Desktop/NLP/finetune/archive/*.csv')\n",
    "\n",
    "# 添加调试信息\n",
    "print(f\"CSV文件列表: {csv_files}\")\n",
    "print(f\"输出目录: {output_base_dir}\")\n",
    "\n",
    "# 遍历处理每个CSV文件\n",
    "for csv_file in tqdm(csv_files, desc=\"转换CSV文件\"):\n",
    "    try:\n",
    "        # 获取文件名（不含扩展名）\n",
    "        file_name = os.path.splitext(os.path.basename(csv_file))[0]\n",
    "        \n",
    "        if file_name in ['reward_train']:\n",
    "            print(f\"处理文件: {csv_file}\")\n",
    "            \n",
    "            # 设置输出路径\n",
    "            output_path = os.path.join(output_base_dir, file_name)\n",
    "            \n",
    "            # 使用pandas读取CSV文件并显示信息\n",
    "            df = pd.read_csv(csv_file)\n",
    "            print(f\"数据行数: {len(df)}\")\n",
    "            \n",
    "            # 将清理后的数据转换为datasets格式\n",
    "            # 修改这里：使用正确的load_dataset参数\n",
    "            dataset = load_dataset('csv', data_files={'train': csv_file})\n",
    "            \n",
    "            # 保存为arrow格式\n",
    "            dataset.save_to_disk(output_path)\n",
    "            \n",
    "            # 验证文件是否成功保存\n",
    "            if os.path.exists(output_path):\n",
    "                print(f\"文件已成功保存到: {output_path}\")\n",
    "                \n",
    "                # 尝试加载保存的数据集\n",
    "                loaded_dataset = load_from_disk(output_path)\n",
    "                print(f\"成功加载数据集，列名: {loaded_dataset.column_names}\")\n",
    "            else:\n",
    "                print(f\"保存失败，文件不存在: {output_path}\")\n",
    "            \n",
    "            print(f\"成功转换: {file_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理文件 {file_name} 时出错: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换CSV文件:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20d35677c7548aa830a411e1b9a5c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换CSV文件:  11%|█         | 1/9 [00:01<00:08,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理文件 finetune_test 时出错: An error occurred while generating the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c48ac6591d64d00a2b2d34325cbd499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/2066589 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换CSV文件:  22%|██▏       | 2/9 [00:02<00:08,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功转换: finetune_train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e67e9135854ab3a8398fe7e3eead6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换CSV文件:  33%|███▎      | 3/9 [00:02<00:04,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功转换: finetune_validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287362ee3d0648eca13d29bf0874ba6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换CSV文件:  44%|████▍     | 4/9 [00:02<00:03,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功转换: pretrain_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79826790755242559ac10035d00d097b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/361420 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换CSV文件:  56%|█████▌    | 5/9 [00:03<00:02,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功转换: pretrain_train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3e02dafeab47ad86149dd372d84872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换CSV文件:  67%|██████▋   | 6/9 [00:03<00:01,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功转换: pretrain_validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d191e320d74973ae8376e019fd48e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换CSV文件:  78%|███████▊  | 7/9 [00:04<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功转换: reward_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b34630f96d4feaa4af50f67be78f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换CSV文件:  89%|████████▉ | 8/9 [00:04<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功转换: reward_train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f31cdf5c96c405f8fca54f9194ce14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换CSV文件: 100%|██████████| 9/9 [00:04<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功转换: reward_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 创建输出目录\n",
    "output_base_dir = 'D:/Desktop/NLP/finetune/archive_arrow'\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "# 获取所有CSV文件\n",
    "csv_files = glob.glob('D:/Desktop/finetune/archive/*.csv')\n",
    "\n",
    "# 遍历处理每个CSV文件\n",
    "for csv_file in tqdm(csv_files, desc=\"转换CSV文件\"):\n",
    "    try:\n",
    "        # 获取文件名（不含扩展名）\n",
    "        file_name = os.path.splitext(os.path.basename(csv_file))[0]\n",
    "        \n",
    "        # 设置输出路径\n",
    "        output_path = os.path.join(output_base_dir, file_name)\n",
    "        \n",
    "        # 加载并转换单个CSV文件\n",
    "        dataset = load_dataset('csv', data_files=csv_file)\n",
    "        \n",
    "        # 保存为arrow格式\n",
    "        dataset.save_to_disk(output_path)\n",
    "        \n",
    "        print(f\"成功转换: {file_name}\")\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理文件 {file_name} 时出错: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': ['instruction', 'output']}\n",
      "数据集格式: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'output'],\n",
      "        num_rows: 2066589\n",
      "    })\n",
      "})\n",
      "\n",
      "数据集大小: 2066589 条\n",
      "\n",
      "数据集特征: {'instruction': Value(dtype='string', id=None), 'output': Value(dtype='string', id=None)}\n",
      "\n",
      "数据样例:\n",
      "{'instruction': ['血热的临床表现是什么?', '帕金森叠加综合征的辅助治疗有些什么？', '卵巢癌肉瘤的影像学检查有些什么？'], 'output': ['初发或复发病不久。皮疹发展迅速，呈点滴状、钱币状或混合状。常见丘疹、斑丘疹、大小不等的斑片，潮红、鲜红或深红色。散布于体表各处或几处，以躯干、四肢多见，亦可先从头面开始，逐渐发展至全身。新皮疹不断出现，表面覆有银白色鳞屑，干燥易脱落，剥刮后有点状出血。可有同形反应;伴瘙痒、心烦口渴。大便秘结、小便短黄，舌质红赤，苔薄黄或根部黄厚，脉弦滑或滑数。血热炽盛病机，主要表现在如下四个面：一、热象：血热多属阳盛则热之实性、热性病机和病证、并表现出热象。二、血行加速：血得热则行，可使血流加速，且使脉道扩张，络脉充血，故可见面红目赤，舌色深红（即舌绛）等症。三、动血：在血行加速与脉道扩张的基础上，血分有热，可灼伤脉络，引起出血，称为“热迫血妄行”，或称动血。四、扰乱心神：血热炽盛则扰动心神，心主血脉而藏神，血脉与心相通，故血热则使心神不安，而见心烦，或躁扰发狂等症。', '综合治疗；康复训练；生活护理指导；低频重复经颅磁刺激治疗', '超声漏诊；声像图；MR检查；肿物超声；术前超声；CT检查']}\n",
      "\n",
      "列统计信息:\n",
      "列名: instruction\n",
      "数据类型: Value(dtype='string', id=None)\n",
      "非空值数量: 2066589\n",
      "---\n",
      "列名: output\n",
      "数据类型: Value(dtype='string', id=None)\n",
      "非空值数量: 2066588\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# 加载数据集\n",
    "dataset_path = \"D:/Desktop/finetune/archive_arrow/finetune_train\"  # 替换为你的路径\n",
    "dataset = load_from_disk(dataset_path)\n",
    "\n",
    "print(dataset.column_names)\n",
    "# 显示基本信息\n",
    "print(f\"数据集格式: {dataset}\")\n",
    "print(f\"\\n数据集大小: {len(dataset['train'])} 条\")\n",
    "print(f\"\\n数据集特征: {dataset['train'].features}\")\n",
    "\n",
    "# 显示前几条数据\n",
    "print(\"\\n数据样例:\")\n",
    "print(dataset['train'][:3])\n",
    "\n",
    "# 显示每个列的数据类型和非空值数量\n",
    "print(\"\\n列统计信息:\")\n",
    "for column in dataset['train'].features:\n",
    "    non_null_count = sum(1 for x in dataset['train'][column] if x is not None)\n",
    "    print(f\"列名: {column}\")\n",
    "    print(f\"数据类型: {dataset['train'].features[column]}\")\n",
    "    print(f\"非空值数量: {non_null_count}\")\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
